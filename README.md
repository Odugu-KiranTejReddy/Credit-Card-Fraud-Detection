# ğŸ•µï¸â€â™‚ï¸ Credit Card Fraud Detection using Machine Learning  
A complete end-to-end project for detecting fraudulent credit card transactions using the popular **Kaggle Credit Card Fraud Dataset**.  
This project includes:

âœ… Data preprocessing  
âœ… Handling class imbalance  
âœ… Feature scaling  
âœ… Model training (XGBoost / Random Forest fallback)  
âœ… Threshold tuning for best F1-score  
âœ… Model evaluation (F1, Precision, Recall, ROC-AUC, PR-AUC, RMSE, MAE)  
âœ… Predicting user-given transactions  
âœ… Saving & loading trained models  

---

## ğŸ“Œ Project Overview

Financial fraud is a major concern in the digital world. Fraudulent transactions are extremely rare (â‰ˆ0.17%), making fraud detection an **imbalanced classification problem**.

This project trains a supervised machine learning model to classify:  
- `0` â†’ Legitimate Transaction  
- `1` â†’ Fraudulent Transaction  

The model uses **XGBoost** (if available) or **Random Forest** as fallback.

---

## ğŸš€ Features

âœ” Processes raw dataset  
âœ” Cleans missing & invalid values  
âœ” Scales important columns (`Time`, `Amount`)  
âœ” Handles imbalance using `scale_pos_weight`  
âœ” Trains ML model using a clean pipeline  
âœ” Finds the **best probability threshold** using F1 optimization  
âœ” Evaluates model on multiple metrics  
âœ” Saves model using `joblib`  
âœ” Predicts user-provided transaction in real time  

---

## ğŸ“‚ Dataset  
This project uses the public Kaggle dataset:

**Credit Card Fraud Detection Dataset**  
Link: https://www.kaggle.com/mlg-ulb/creditcardfraud

- 284,807 transactions  
- 492 frauds (0.172%)  
- Features `V1`â€“`V28` are PCA-transformed  
- Includes `Time`, `Amount`, and `Class`
- ## ğŸ§  Model

The training code automatically selects:

### âœ… **XGBoostClassifier**  
If installed, uses:
- 800 estimators  
- scale_pos_weight (for class imbalance)  
- learning rate: 0.05  
- max_depth: 4  

### âœ… **RandomForestClassifier**  
Fallback option with:
- 800 trees  
- Balanced subsample class weights  

---

## ğŸ“Š Metrics Used

The model prints all key metrics:

- **F1-score** (primary metric)  
- **Precision**
- **Recall**
- **Balanced Accuracy**
- **ROC-AUC**
- **PR-AUC** (Average Precision)
- **RMSE** (proba vs true label)
- **MAE** (proba vs true label)

These metrics ensure robustness for highly imbalanced fraud detection.

---

## ğŸ“ˆ Threshold Tuning

Instead of using a default 0.5 probability threshold, the model finds the **best threshold** that maximizes F1-score on the validation set.
